{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05b256f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [07/Aug/2021 10:50:05] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [07/Aug/2021 10:50:05] \"GET /static/css/styles.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [07/Aug/2021 10:50:05] \"GET /static/bootstrap/css/bootstrap.min.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [07/Aug/2021 10:50:05] \"GET /static/bootstrap/js/bootstrap.min.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [07/Aug/2021 10:50:05] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [07/Aug/2021 10:50:13] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [07/Aug/2021 10:50:13] \"GET /static/bootstrap/css/bootstrap.min.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [07/Aug/2021 10:50:13] \"GET /static/css/styles.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [07/Aug/2021 10:50:13] \"GET /static/bootstrap/js/bootstrap.min.js HTTP/1.1\" 304 -\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "import re\n",
    "from nltk.corpus import shakespeare\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from flask import Flask, render_template, request\n",
    "\n",
    "app = Flask(__name__, static_url_path='/static')\n",
    "app.secret_key = 'key'\n",
    "\n",
    "NLPDoc = shakespeare.words('hamlet.xml')\n",
    "for i in range(len(NLPDoc)):\n",
    "    NLPDoc[i] = NLPDoc[i].lower()\n",
    "\n",
    "punctuation = re.compile(r'[-.?!,:;()|0-9]')\n",
    "post_punctuation = []\n",
    "for words in NLPDoc:\n",
    "    word = punctuation.sub(\"\",words)\n",
    "    if len(word)>0:\n",
    "        post_punctuation.append(word)\n",
    "        \n",
    "new_token = []\n",
    "for word in post_punctuation:\n",
    "    if word not in stopwords.words('english'):\n",
    "        new_token.append(word)\n",
    "\n",
    "@app.route('/')\n",
    "@app.route('/home')\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():    \n",
    "    check = request.form['sentence']\n",
    "    check_tokens = word_tokenize(check)\n",
    "    \n",
    "    check_last = check_tokens[len(check_tokens)-1]\n",
    "    check_idx = len(check_last)\n",
    "    \n",
    "    res = [idx for idx in new_token if idx[0:check_idx] == check_last.lower()]  \n",
    "    \n",
    "    distinct_count = FreqDist()\n",
    "    for word in res:\n",
    "        distinct_count[word.lower()]+=1\n",
    "    result = distinct_count.most_common(10)\n",
    "    \n",
    "    check_tokens[len(check_tokens)-1] = result[0][0]\n",
    "    \n",
    "    check_str_final = TreebankWordDetokenizer().detokenize(check_tokens)\n",
    "    \n",
    "    return render_template('index.html', result=result, check_str=check_str_final)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
